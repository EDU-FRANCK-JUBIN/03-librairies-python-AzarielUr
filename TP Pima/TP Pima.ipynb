{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSE PREDICTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: \n",
      "(768, 9)\n",
      "\n",
      "Colonnes:\n",
      "Index(['pregnant', 'diastolic', 'triceps', 'bodymass', 'pedigree', 'age',\n",
      "       'plasma', 'serum', 'diabete'],\n",
      "      dtype='object')\n",
      "\n",
      "Types\n",
      "pregnant       int64\n",
      "diastolic      int64\n",
      "triceps        int64\n",
      "bodymass     float64\n",
      "pedigree     float64\n",
      "age            int64\n",
      "plasma         int64\n",
      "serum          int64\n",
      "diabete       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Importation des données\n",
    "\n",
    "#utilisation de la librairie Pandas\n",
    "#spécialisée - entres autres - dans la manipulation des données\n",
    "\n",
    "# Pandas : Python Data Analysis Library. Très\n",
    "# pratique pour la manipulation des données, avec\n",
    "# un type data.frame inspiré de R\n",
    "\n",
    "import pandas\n",
    "#header = 0, la première ligne (n°0) correspond aux noms de variables\n",
    "pima = pandas.read_table(\"pima.txt\",sep=\"\\t\",header=0)\n",
    "\n",
    "#dimensions\n",
    "# 768 lignes (obs.) et 9 colonnes (variables)\n",
    "print(\"Dimensions: \")\n",
    "print(pima.shape)\n",
    "\n",
    "#liste des colonnes\n",
    "print(\"\\nColonnes:\")\n",
    "print(pima.columns)\n",
    "\n",
    "#liste des colonnes et leurs types\n",
    "print(\"\\nTypes\")\n",
    "print(pima.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 8) (300, 8) (468,) (300,)\n"
     ]
    }
   ],
   "source": [
    "## Subdivision en échantillons d’apprentissage et de test\n",
    "\n",
    "#transformation en matrice numpy - seul reconnu par scikit-learn\n",
    "data = pima.values\n",
    "\n",
    "#X matrice des var. explicatives\n",
    "X = data[:,0:8]\n",
    "\n",
    "#y vecteur de la var. à prédire\n",
    "y = data[:,8]\n",
    "\n",
    "#utilisation du module model_selection de scikit-learn (sklearn)\n",
    "from sklearn import model_selection\n",
    "\n",
    "#subdivision des données – éch.test = 300 ; éch.app = 768 – éch.test = 468\n",
    "X_app,X_test,y_app,y_test = model_selection.train_test_split(X,y,test_size = 300,random_state=0)\n",
    "print(X_app.shape,X_test.shape,y_app.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.75153769e-02 -1.59511103e-02  1.70428483e-03  5.18609374e-02\n",
      "   5.34696503e-01  1.24335202e-02  2.40115458e-02 -2.91586161e-04]] [-5.13527961]\n"
     ]
    }
   ],
   "source": [
    "## Construction du modèle sur l’échantillon d’apprentissage\n",
    "\n",
    "#à partir du module linear_model du package sklearn\n",
    "#importer la classe LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#exécution de l'instance sur les données d'apprentissage\n",
    "#c.à-d. construction du modèle prédictif\n",
    "modele = lr.fit(X_app,y_app)\n",
    "\n",
    "#les sorties sont très pauvres à la différence des logiciels de stat\n",
    "#les coefficients…\n",
    "print(modele.coef_,modele.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184  17]\n",
      " [ 45  54]]\n",
      "\n",
      "Taux de succès:\n",
      "0.7933333333333333\n",
      "\n",
      "Taux d'erreur:\n",
      "0.20666666666666667\n",
      "\n",
      "Sensibilité:\n",
      "0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "## Prédiction et évaluation sur l’échantillon test\n",
    "\n",
    "#prediction sur l'échantillon test\n",
    "y_pred = modele.predict(X_test)\n",
    "\n",
    "#importation de metrics - utilisé pour les mesures de performances\n",
    "from sklearn import metrics\n",
    "\n",
    "#matrice de confusion\n",
    "#confrontation entre Y obs. sur l’éch. test et la prédiction\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "\n",
    "#taux de succès\n",
    "acc = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nTaux de succès:\")\n",
    "print(acc)\n",
    "\n",
    "#taux d'erreur\n",
    "err = 1.0 - acc\n",
    "print(\"\\nTaux d'erreur:\")\n",
    "print(err)\n",
    "\n",
    "#sensibilité (ou rappel)\n",
    "se = metrics.recall_score(y_test,y_pred,pos_label='positive')\n",
    "print(\"\\nSensibilité:\")\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154228855721394\n"
     ]
    }
   ],
   "source": [
    "## Construction de sa propre mesure de performance (ex. Spécificité)\n",
    "\n",
    "#écrire sa propre func. d'éval - ex. specificité\n",
    "def specificity(y,y_hat):\n",
    "    \n",
    "    #matrice de confusion – un objet numpy.ndarray\n",
    "    mc = metrics.confusion_matrix(y,y_hat)\n",
    "\n",
    "    #’’negative’’ est sur l'indice 0 dans la matrice\n",
    "    import numpy\n",
    "    res = mc[0,0]/numpy.sum(mc[0,:])\n",
    "    return res\n",
    "\n",
    "#la rendre utilisable - transformation en objet scorer\n",
    "specificite = metrics.make_scorer(specificity,greater_is_better=True)\n",
    "\n",
    "#utilisation de l’objet scorer\n",
    "#remarque : modele est le modèle élaboré sur l’éch. d’apprentissage\n",
    "sp = specificite(modele,X_test,y_test)\n",
    "print(sp) # 0.915 = 184 / (184 + 17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION CROISÉE\n",
    "\n",
    "Problème : lorsque l’on traite un petit fichier (en nombre d’obs.), le schéma apprentissage – test est pénalisant <br/>\n",
    "apprentissage : on réduit l’information disponible pour créer le modèle ; <br/>\n",
    "test : un faible effectif produit des estimationsdes performances très instables). <br/>\n",
    "\n",
    "Solution : <br/>\n",
    "(1) construire le modèle sur la totalité des données, <br/>\n",
    "(2) évaluer les performances à l’aide des techniques de ré-échantillonnage (ex. validation croisée)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.17087631e-01 -1.68947770e-02  7.46053001e-04  5.97221654e-02\n",
      "   6.81392866e-01  7.21999666e-03  2.83788475e-02 -6.42978367e-04]] [-5.88988049]\n",
      "[0.74025974 0.75324675 0.79220779 0.72727273 0.74025974 0.74025974\n",
      " 0.81818182 0.79220779 0.73684211 0.82894737]\n",
      "0.7669685577580314\n"
     ]
    }
   ],
   "source": [
    "#importer la classe LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#exécution de l'instance sur la totalité des données (X,y)\n",
    "modele_all = lr.fit(X,y)\n",
    "\n",
    "#affichage\n",
    "print(modele_all.coef_,modele_all.intercept_)\n",
    "\n",
    "#utilisation du module model_selection\n",
    "from sklearn import model_selection\n",
    "\n",
    "#évaluation en validation croisée : 10 cross-validation\n",
    "succes = model_selection.cross_val_score(lr,X,y,cv=10,scoring='accuracy')\n",
    "\n",
    "#détail des itérations\n",
    "print(succes)\n",
    "\n",
    "#moyenne des taux de succès = estimation du taux de succès en CV\n",
    "print(succes.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORING\n",
    "\n",
    "Ex. de ciblage : faire la promotion d’un produit auprès d’un ensemble de clients <br/>\n",
    "Objectif : contacter le moins de personnes possible, obtenir le max. d’achats <br/>\n",
    "Démarche : attribuer un score aux individus, les trier de manière décroissante (score élevé = forte appétence au produit), estimer à l’aide de la courbe de gain le nombre d’achats en fonction d’une taille de cible choisie. <br/>\n",
    "Remarque : L’idée peut être transposée à d’autres domaines (ex. dépistage de maladie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Construction de la courbe de gain\n",
    "\n",
    "#classe Régression Logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#modélisation sur les données d'apprentissage\n",
    "modele = lr.fit(X_app,y_app)\n",
    "\n",
    "#calcul des probas d'affectation sur ech. test\n",
    "probas = lr.predict_proba(X_test)\n",
    "\n",
    "#score de 'presence'\n",
    "score = probas[:,1]\n",
    "\n",
    "#transf. en 0/1 de Y_test\n",
    "pos = pandas.get_dummies(y_test).values\n",
    "\n",
    "#on ne récupère que la 2è colonne (indice 1)\n",
    "pos = pos[:,1]\n",
    "\n",
    "#nombre total de positif\n",
    "import numpy\n",
    "npos = numpy.sum(pos)\n",
    "\n",
    "#index pour tri selon le score croissant\n",
    "index = numpy.argsort(score)\n",
    "\n",
    "#inverser pour score décroissant – on s’intéresse à forte proba. en priorité\n",
    "index = index[::-1]\n",
    "\n",
    "#tri des individus (des valeurs 0/1)\n",
    "sort_pos = pos[index]\n",
    "\n",
    "#somme cumulée\n",
    "cpos = numpy.cumsum(sort_pos)\n",
    "\n",
    "#rappel\n",
    "rappel = cpos/npos\n",
    "\n",
    "#nb. obs ech.test\n",
    "n = y_test.shape[0]\n",
    "\n",
    "#taille de cible – séquence de valeurs de 1 à 300 avec un pas de 1\n",
    "taille = numpy.arange(start=1,stop=301,step=1)\n",
    "\n",
    "#passer en proportion\n",
    "taille = taille / n\n",
    "\n",
    "#graphique avec matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#titre et en-têtes\n",
    "plt.title('Courbe de gain')\n",
    "plt.xlabel('Taille de cible')\n",
    "plt.ylabel('Rappel')\n",
    "\n",
    "#limites en abscisse et ordonnée\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "#astuce pour tracer la diagonale\n",
    "plt.scatter(taille,taille,marker='.',color='blue')\n",
    "\n",
    "#insertion du couple (taille, rappel)\n",
    "plt.scatter(taille,rappel,marker='.',color='red')\n",
    "\n",
    "#affichage\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH\n",
    "\n",
    "Problème : De nombreux algorithmes demachine learning reposent sur des paramètres qui ne sont pas toujours évidents à déterminer pour obtenir les meilleurs performances sur un jeu de données à traiter. Ex. SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201   0]\n",
      " [ 99   0]]\n",
      "\n",
      "Succès:\n",
      "0.67\n"
     ]
    }
   ],
   "source": [
    "## Dépendances des algorithmes d’apprentissage aux paramètres\n",
    "\n",
    "#svm\n",
    "from sklearn import svm\n",
    "\n",
    "#par défaut un noyau RBF et C = 1.0\n",
    "mvs = svm.SVC(gamma='auto')\n",
    "\n",
    "#modélisation\n",
    "modele2 = mvs.fit(X_app,y_app)\n",
    "\n",
    "#prédiction ech. test\n",
    "y_pred2 = modele2.predict(X_test)\n",
    "\n",
    "#matrice de confusion\n",
    "print(metrics.confusion_matrix(y_test,y_pred2))\n",
    "\n",
    "#succès en test\n",
    "print('\\nSuccès:')\n",
    "print(metrics.accuracy_score(y_test,y_pred2))\n",
    "\n",
    "#C’est la méthode (SVM) qui est inapte ou c’est le paramétrage qui est inadapté ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           params  mean_test_score\n",
      "0     {'C': 0.1, 'kernel': 'rbf'}         0.638889\n",
      "1  {'C': 0.1, 'kernel': 'linear'}         0.752137\n",
      "2       {'C': 1, 'kernel': 'rbf'}         0.638889\n",
      "3    {'C': 1, 'kernel': 'linear'}         0.747863\n",
      "4      {'C': 10, 'kernel': 'rbf'}         0.638889\n",
      "5   {'C': 10, 'kernel': 'linear'}         0.756410\n",
      "\n",
      "Meileur paramétrage:\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Meileure performance:\n",
      "0.7564102564102564\n",
      "\\Succès:\n",
      "0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "## Détermination des meilleurs valeurs des paramètres\n",
    "\n",
    "# Stratégie : Grille de recherche. On indique les paramètres à faire varier, scikit-learn les croise et mesure\n",
    "# les performances en validation croisée.\n",
    "\n",
    "#import de la classe\n",
    "from sklearn import model_selection\n",
    "\n",
    "#combinaisons de paramètres à évaluer\n",
    "parametres = [{'C':[0.1,1,10],'kernel':['rbf','linear']}]\n",
    "\n",
    "#évaluation en validation croisée de 3 x 2 = 6 configurations\n",
    "#accuracy sera le critère à utiliser pour sélectionner la meilleure config\n",
    "#mvs est l’instance de la classe svm.SVC (cf. page précédente)\n",
    "grid = model_selection.GridSearchCV(estimator=mvs,param_grid=parametres,scoring='accuracy')\n",
    "\n",
    "#lancer la recherche – attention, gourmand en calculs\n",
    "grille = grid.fit(X_app,y_app)\n",
    "\n",
    "#résultat pour chaque combinaison\n",
    "print(pandas.DataFrame.from_dict(grille.cv_results_).loc[:,[\"params\",\"mean_test_score\"]])\n",
    "\n",
    "#meilleur paramétrage\n",
    "print(\"\\nMeileur paramétrage:\")\n",
    "print(grille.best_params_)\n",
    "\n",
    "#meilleur performance – estimée en interne par validation croisée\n",
    "print(\"\\nMeileure performance:\")\n",
    "print(grille.best_score_)\n",
    "\n",
    "#prédiction avec le modèle « optimal » c.-à-d. {‘C’ : 10, ‘kernel’ : ‘linear’}\n",
    "y_pred3 = grille.predict(X_test)\n",
    "\n",
    "#taux de succès en test\n",
    "print(\"\\nSuccès:\")\n",
    "print(metrics.accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECTION DE VARIABLES\n",
    "\n",
    "Objectif : la sélection de variables - la recherche de modèles parcimonieux - présente plusieurs avantages : interprétation, déploiement (moins de var. à renseigner), performances en généralisation (ou du moins maintien des performances). <br/>\n",
    "Méthode : Nous implémentons la méthode RFE de scikit-learn : elle élimine au fur et à mesure les coefficients les plus faibles en valeur absolue (étrange : les variables ne sont pas toujours à la même échelle ??? une standardisation des variables paraît nécessaire), et s’arrête quand on arrive à la moitié ou à un nombre spécifié de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb de valeurs:\n",
      "4\n",
      "\n",
      "Variables:\n",
      "[ True False False  True  True False  True False]\n",
      "\n",
      "Ordre de suppression:\n",
      "[1 2 4 1 1 3 1 5]\n",
      "\n",
      "Succès après réévaluation:\n",
      "0.7866666666666666\n"
     ]
    }
   ],
   "source": [
    "## Sélection de variables\n",
    "\n",
    "#importer la classe LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#algorithme de sélection de var.\n",
    "from sklearn.feature_selection import RFE\n",
    "selecteur = RFE(estimator=lr)\n",
    "\n",
    "#lancer la recherche\n",
    "sol = selecteur.fit(X_app,y_app)\n",
    "\n",
    "#nombre de var. sélectionnées\n",
    "print(\"\\nNb de valeurs:\")\n",
    "print(sol.n_features_)\n",
    "\n",
    "#liste des variables sélectionnées\n",
    "# Variables sélectionnées : pregnant, bodymass, pedigree, plasma.\n",
    "\n",
    "print(\"\\nVariables:\")\n",
    "print(sol.support_)\n",
    "\n",
    "#ordre de suppression\n",
    "print(\"\\nOrdre de suppression:\")\n",
    "print(sol.ranking_) \n",
    "\n",
    "# Serum a été retirée en premier, puis triceps, puis âge, puis diastolic. Les variables restantes sont indexées 1.\n",
    "\n",
    "#réduction de la base d'app. aux var. sélectionnées\n",
    "#en utilisant le filtre booléen sol.support_\n",
    "X_new_app = X_app[:,sol.support_]\n",
    "\n",
    "#construction du modèle sur les explicatives sélectionnées\n",
    "modele_sel = lr.fit(X_new_app,y_app)\n",
    "\n",
    "#réduction de la base test aux mêmes variables\n",
    "X_new_test = X_test[:,sol.support_]\n",
    "\n",
    "#prédiction du modèle réduit sur l’éch. test\n",
    "y_pred_sel = modele_sel.predict(X_new_test)\n",
    "\n",
    "#évaluation\n",
    "print(\"\\nSuccès après réévaluation:\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_sel))\n",
    "\n",
    "#Aussi bien (presque, 0.793) que le modèle initial, mais avec moitié moins de variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
